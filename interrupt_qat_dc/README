./setup.sh
./build.sh
./run.sh
./parse.sh

---
Implicit batching performed by response ring poller (batch-devolve)
(base) n869p538@sapphire:qatlib$ ./chaining_sample | tee respts.log.2
(base) n869p538@sapphire:qatlib$ grep IDX respts.log.1 | awk '/IDX/{ if( $4 > sync_p ){ good+=1  } else { bad+=1 } ; sync_p=$7 } END{printf("%s\n", (bad)/(bad + good))}'
0.90625

---

---
Enc Throughput on Calgary For Different Synchronous Batch Sizes 256KB Payload Fragmented and Submitted Asynchronously w/ packets fwded in callback (origin/callback-enc)
```
(base) n869p538@sapphire:qatlib$ ./chaining_sample | tee enc-bw.log
(base) n869p538@sapphire:qatlib$ grep -E -e '[0-9]+ [0-9]+' -e 'BW' enc-bw.log | awk '/[0-9]+ [0-9]+/{if(ctr > 0 ){printf("%f\n", sum/ctr);}; printf("%s,%s,",$1,$2); sum=0; avg=0;c
tr=0} /BW/{sum+=$2;ctr+=1;} END{printf("%f\n", sum/ctr);}'
```

---
Comp Throughput on Calgary For Different Synchronous Batch Sizes 256KB Payload Fragmented and Submitted Asynchronously w/ packets fwded in callback (origin/callback-comp)
```
./chaining_sample  | tee comp-bw.1
grep -E -e '[0-9]+,[0-9]+' -e 'BW' comp-bw.1 | awk '/[0-9]+,[0-9]+/{if(ctr > 0 ){printf("%f\n", sum/ctr);}; printf("%s,",$1); sum=0; avg=0;ctr=0} /BW/{sum+=$2;ctr+=1;} END{printf("%f\n", sum/ctr);}'
```
---


Chained Throughput on Calgary For Different Synchronous Batch Sizes 256KB Payload Fragmented and Submitted Asynchronously w/ packets fwded in callback (origin/call-back-batch-synchronization)
```
./chaining_sample  >& chained-comp-enc-bw.1
grep -E -e '[0-9]+ [0-9]+' -e 'BW' chained-bw.log | awk '/[0-9]+ [0-9]+/{if(ctr > 0 ){printf("%f\n", sum/ctr);}; printf("%s,%s,",$1,$2); sum=0; avg=0;ctr=0} /BW/{sum+=$2;ctr+=1;} END{printf("%f\n", sum/ctr);}'
```

Encryption Throughput On Calgary For Different Synchronous Batch Sizes 256KB Payload Fragmented and Submitted Asynchronously (origin/enc-serialized-individual)
 ```
./chaining_sample | tee enc_serial.log
 grep -E -e '[0-9]+,[0-9]+' -e 'DC-BW' enc_serial.log | awk '/[0-9]+,[0-9]+/{if(ctr > 0 ){printf("%f\n", sum/ctr);}; printf("%s,",$1); sum=0; avg=0;ctr=0} /DC/{sum+=$2;ctr+=1;} END{printf("%f\n", sum/ctr);}' > enc_serialized.txt
./chaining_sample  | tee sync_enc_serial.log
```

---
Compression Throughput On Calgary For Different Synchronous Batch Sizes 256KB Payload Fragmented and Submitted Asynchronously (origin/comp-only)
```
./chaining_sample | tee serialized-bw.log
# FragmentSize, numFragments, BW(MB/s)
grep -E -e '[0-9]+,[0-9]+' -e 'DC-BW' serialized-bw.log | awk '/[0-9]+,[0-9]+/{if(ctr > 0 ){printf("%f\n", sum/ctr);}; printf("%s,",$1); sum=0; avg=0;ctr=0} /DC/{sum+=$2;ctr+=1;} END{printf("%f\n", sum/ctr);}' > serialized.txt
```
---

---
Just Compression Throughput(comp-only)
```
(base) n869p538@sapphire:qatlib$ git branch comp-only
(base) n869p538@sapphire:qatlib$ sudo make samples -j
(base) n869p538@sapphire:qatlib$ ./.libs/chaining_sample
DC-BW(MB/s): 1087
DC-BW(MB/s): 1089
DC-BW(MB/s): 1084
```

----
AES+SHA Penalty Factor(hash-pen-factor)

```sh
(base) n869p538@sapphire:qatlib$ cat /etc/sysconfig/qat
# Comment or remove next line to disable sriov
#SRIOV_ENABLE=1
POLICY=1
ServicesEnabled=sym;dc
(base) n869p538@sapphire:qatlib$ sudo systemctl restart qat

./cpa_sample_code runTests=1 | tee aes_sha_async_sync_enc.log
grep -e 'Throughput' aes_sha_async_sync_enc.log  | awk '{print $2}' | tee txt
# prints sync bandwidths, then async bandwidths for sizes 1KB-256KB
```

----

----
Penalty Factor Using Comp BW Comparison Using Async Comp Throughput: (comp_pen_factor)
./cpa_sample_code runTests=32 | tee async_comp.log
grep -e 'Throughput' async_comp.log  | awk '{print $2}'
----

----
Chained Hash then Compress Throughput single inst for each functino (hash_comp_pipeline_throughput)
(base) n869p538@sapphire:qatlib$ ./.libs/chaining_sample
----

---
Polling thread Hashing throughput: hash_only_throughput 
When polling for responses on a separate thread, we observe ~1GB/s bandwidth, though this is much lower than the throughput reported in `pipeline_payload_throughput`
What is the difference in these setups? (Hypo is that pipeline_payload_throughput is buggy, we expect ~8000Mbit/s bw)
```
BW(MB/s): 1165
BW(MB/s): 1166
```
---

---
SYNC_BANDWIDTH_SWEEP (branch max_bandwidth_multi_inst_sync_vs_async)
===
./cpa_sample runTests=32
---


---
Max Achievable Bandwidth Per Instance (branch: max_throughput_single_inst)
===
sudo ./cpa_sample_code runTests=1

sudo ./cpa_sample_code runTests=32
grep -e Direction -e Packet -e Throughput dec_max_band.log
---

---
Host-Managed SW Chaining Performance: (branch: sw_chained_request_population_and_submission_brkdown)
====
./run_sw_hash_and_compress.sh
(base) n869p538@sapphire:qatlib$ for i in `seq 10 21`; do grep -A4 "Buf_Size: $((1 << i )) " sw_hash_comp.log | grep DC-App | awk '{sum+=$2} END{prin
t sum/NR}'; done
(base) n869p538@sapphire:qatlib$ for i in `seq 10 21`; do grep -A4 "Buf_Size: $((1 << i )) " sw_hash_comp.log | grep DC-Poll | awk '{sum+=$2} END{pri
nt sum/NR}'; done
# Change second grep to 'Hash-App' and 'Hash-Poll' for Hash app-layer breakdowns

./run_hw_hash_and_compress.sh
(base) n869p538@sapphire:qatlib$ for i in `seq 10 21`; do grep -A3 "Buf_Size: $((1 << i )) " hw_hash_comp.log | grep User-Submit-Time | awk '{sum+=$2} END{print sum/NR}' ; done
(base) n869p538@sapphire:qatlib$ for i in `seq 10 21`; do grep -A3 "Buf_Size: $((1 << i )) " hw_hash_comp.log | grep User-Poll-Time | awk '{sum+=$2} END{print sum/NR}' ; done

(base) n869p538@sapphire:qatlib$ grep Ave sw_hash_comp.log # WHy are average req/sub times always a multiple of 10?
Sym-Average time to submit request: 90.000000
Sym-Average time to create request: 270.000000
DC-Average time to submit request: 110.000000
DC-Average time to create request: 160.000000
---


Observations:
Obs: Decompression throughput is extremely sensitive to system noise (e.g., contention on the DDIO ways). On a mostly idle server 
Obs: We observe that hardware chaining of the hash and compress functions takes roughly the same amount of time as performing a single compression operation. We hypothesize that the two functions are performed in parallel or are pipelined with the input to the hash function passed to the compress function after SHA256 processing.
Observation: Static Async Deflate Decomp gets lower 66225Gbit/s throughput than Dynamic HT Async Deflate Decomp with ~119Gbit/s throughput
Obs: Synchronous hashing and decompression takes ~3s and ~2s while Async DC only takes ~ 70us when combined with sync Hash 300215890ns (kept hashing using sync api -- no polling). (Changing cpaDcCompressData2 to use async API with callback followed by polling drops runtime).  Using Async Hash and DC for both reduces (PerformOp + Poll) Time to 19us cumulative exe time: Hash Poll: 8606ns, DC Poll: 11198ns
- Why does synchronocity of one operation affect polling completion time of another? when they do not share resources?

Obs: Sym ops have a different control path for synchronous operations: https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_request_population_and_submission_brkdown/quickassist/lookaside/access_layer/src/common/crypto/sym/lac_sym_api.c#L1023
Obs: Synchronous calls to dc and sym ops do not require polling the instance for dc stateless and hash ops chaining function
Obs: Synchronous calls to dcc sessions/instances require polling the instance after the dcChainPerformOp call (Application submission function call)

Obs: The call to perform a hash operation takes longer than polling for completion, though polling is required to ensure offload completion
```
# measuring offload time with dc/cpaCySymPerformOp (populate and submit) && polling
Iteration: 168
Hash Poll: 10455
DC Poll: 14326
Iteration: 169
Hash Poll: 10508
DC Poll: 15209

# measuring w/o dc/cpaCySymPerformOp (just time to poll via icp_sal_{Cy/Dc}PollInstance
Iteration: 165
Hash Poll: 1190
DC Poll: 10187
Iteration: 166
Hash Poll: 857
DC Poll: 11008

DC:
Average time to submit request: 50.000000
Average time to create request: 230.000000
15209 - 11008  = ~ 3.5us of unaccounted latency
- from resolving the handle?

```
Why does throughput increase with payload size?
- Hypo: There is a fixed offload cost for starting up the accelerator/algorithm that is not amortized until sufficient payload size is reached
Can prefetching a src and dst buffer pair increase throughput for small payload sizes?
Obs: Library tasked with generating determining which fields and algorithm specific information to use when populating requests for a given operation/algorithm. Many conditional branches that depend on the algorithm/operation being offloaded.(AES, LAC, CCM, XTS)
Question: What is the branch misprediction rate of such code sequences when a single core uses multiple sessions to perform different algorithms?

Obs: Session CTX is smaller for hash-unchained op: 2312B
Obs: Session CTX for stateless compression is smaller: 672B
Observation:
For host-managed chaining, an instance supporting each type of operation must be reserved. Tearing down and reinitializing sessions are long latency operations. Reconfiguring host-managed chains on the fly is infeasible in application critical paths.

Hypotheses:
Hypo:
- The maximum achievable throughput is possible to obtain for some smallest payload size (min_perf_payload_size -- mpps)
- This value depends on offload model, algorithm, and hardware implementation
- For chained offloads, we need the maximum achievable throughput with ordered offloads. The minimal ordered min perf payload size -- ommps determines the throughput of a chained accelerator pipeline that uses on-chip hardware buffers

Questions:

What is the difference between Dynamic HT and Static HT?
Is peak synchronous throughput the same as peak asynchronous throughput for dc/enc?
Why isn't peak performance achieved at an arbitrarily small offload size?
What is the loaded latency for ordered requests for each accelerator?
Disabling smt, turbo boost, and setting the cpu's to use the performance scaling governor gave more consistent results for performOp function times. Why?
What is the unloaded latency? 
Current approach to timing phases is to insert timestamp arrays, collect, and print. Is there a way to tie function calls to perf events such that a timer starts/stops on function call/return?
What is the difference between messages being enq'd or "sent directly" https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_request_population_and_submission_brkdown/quickassist/lookaside/access_layer/src/common/crypto/sym/lac_sym_queue.c#L111
Does Stateless DC example (which uses the async method) , modified to use sync, also see the same ~2s latency?
Does syncSwChain modified to use async with a lightweight callback get lower latency? YES
Does the callback function eventually get called without calling icpPollInstance() ?

How does a synchronous call when using dc or sym ensure that computation is complete when the function returns?
Why does synchronous operation for dc/cy session not require polling, but incur 2-3s latency?
Why does sync op for hash-dc chain session require polling, with lower latency 3us on user-space submit side and 12 us on poll side?

Is chained session CTX size sum of both hash and compress individual ctx's?

```
Each VF enabled for sym, asym, dc
        has 4 instances. Each VF enabled for mixed services like sym;asym,
        sym;dc, asym;dc has 2 instances of each type,
```


Is API-Ref indicating that sync APIs complete operation upon returning?

Why hash before compressing data?

What other enc/dec cots cc ax released? Perf relative to intel?

Latency/Throughput of cy;dc vs. dc only inst for dc ops?

What happens on session initialization?

Impact of using bufferlists instead of a single flatbuffer ? 
Why is there metadata associated with flatbuffers? What does it store? Why has metadata been removed/added across QAT versions?
Do any APIs expect flatbuffers instead of bufferlists ?
Impact of cy/dc with discontiguous buffers in the buffer list vs. contiguous buffers?
BufferList: Why isn't BufferList 8B aligned? pointer to array of flat buffers
FlatBuffer: 16B (Len, PhysAddr) pair
How many levels of indirection are traversed to pass the physical address of payload data to QAT? (1) APIs take a pointer to a BufferList, (2) A pointer dereference resolves the start of the FlatBuffer array, (3) each FlatBuffer entry must be dereferenced to resolve the physical address of the data

Does hash operation write to the passed in buffer list or the Cpa8U* digest buffer specified as a parameter in the opData's pDigestResultField?

Purpose of CpaDcRqResults Structure -- passed to cpaDcCompressData2

Does inplace processing affect latency? Does it reduce cache pollution? Which applications/operations can support in-place processing?
```
cpaCySymPerformOp: dstBufferList Param blurb
This is because, for out-of-place processing, the data outside the regions in the source buffer on which cryptographic operations are performed are copied into the destination buffer. To perform "in-place" processing set the pDstBuffer parameter in cpaCySymPerformOp function to point at the same location as pSrcBuffer. For optimum performance, the data pointed to SHOULD be 8-byte aligned.
```

why would static huffman give better compressibility?
https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_dcc/quickassist/lookaside/access_layer/src/sample_code/functional/dc/stateless_sample/cpa_dc_stateless_sample.c#L918

Is the dataplane API faster? No-intel
```
From a throughput and latency perspective, there is no difference in performance between the
Data Plane API and the traditional API.
```

What is the latency of offload when using interrupt?
```
When operating in interrupt mode, the accelerator will generate an MSI-X interrupt when a
response is placed on a response ring. Each ring bank has a separate MSI-X interrupt which
may be steered to a particular CPU core via the CoreAffinity settings in the configuration file.
```

What does the dcInstance use the intermediate buffers for? 
- we see that number of intermediate buffers for stateless compression is 0

What is the symmetric session context (https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_dcc/quickassist/include/lac/cpa_cy_sym.h#L106) used for?
What is a context buffer used for, where is it stored, and why isn't it needed for stateless compression?
When is the context buffer allocated? Who allocates it? Is it associated with a session or instance? When is the association made?
Hypo: stateful compression stores some state in host memory

Can chained ops append the digest to the destination buffer?

How is output length communicated?

Can the format of the output buffer list be decided by software ? (e.g., use flatbuffers of 4kb size)
YES. The summation of the sizes of the flatbuffers in the flatbufferlist must be larger than or equal in size to the src buf when the cpaCySymPerformOp function is called

Why does the CySym session need to store context for hashing?
* What is the context used for in other Cy Operations ?
* Why have hashing and enc/dec been grouped under the same instance type?
* Hypo: non-static information that may be needed on subsequent operations
```
instanceHandle – Instance handle.
pSymCb – Pointer to callback function to be registered. Set to NULL if the cpaCySymPerformOp function is required to work in a synchronous manner.
pSessionSetupData – Pointer to session setup data which contains parameters which are static for a given cryptographic session such as operation type, mechanisms, and keys for cipher and/or hash operations.
sessionCtx – Pointer to the memory allocated by the client to store the session context. This will be initialized with this function. This value needs to be passed to subsequent processing calls.
```





Impact of session priority?
Is sampleVirtToPhys the best address translation function?

Each individual op in hw managed chain must be checked for valid status -- add this to hwChainedOpPerf


Can hash digest and compression be performed in parallel from software using two sessions?
* digest may or may not be appended to the compressed buffer. does this impact whether the two operations can operate in parallel/pipelined?
Does the hardware do the two ops in parallel or pipeline them?

How does the software distinguish when hardware support for chained operation vs. when software must manage multiple operations?
Hypo: Hardware recognizes descriptor with supported chained op and pipelines.
Test: Chained Compress Then AEAD, followed by chained
Does this mean only Hash_then_compress chained sessions are valid operations?:https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_dcc/quickassist/lookaside/access_layer/src/common/compression/dc_chain.c#L453
Capabilities register indicates what operations a logical instance supports
- 

How are multiple operations performed for host-managed?

Monolithic HW Chaining Performance:
====
Userspace latency measurements: 
git@github.com:neel-patel-1/qatlib.git
```
git checkout user_dcc_chain_timestamps_only
./chaining_sample > user_times.log
grep 'User ' user_times.log  | awk '/Desc/{DescPop+=$5;} /Poll/{Poll+=$4} /Submit/{Submit+=$4} END{printf("UserDescPop(ns):%f,UserSubmitApi:%f,UserPollTime:%f\n",DescPop/(NR/3),Submit/(NR/3),Poll/(NR/3));}'
UserDescPop(ns):36.414880,UserSubmitApi:1222.795712,UserPollTime:10494.133670
36.414880,1222.795712,10494.133670
```

Library-Side Latency Measurements and Session Initialization (branch: dc_chain_sample_app_breakdown )
```sh
sudo make samples -j; ./chaining_sample > sample
grep Library sample | awk '/submit/{subSum+=$4} /create/{createSum+=$5} END{printf("create_desc_lib:%f,sub_desc_lib:%f\n",createSum/(NR/2),subSum/(NR/2))}'
```


Qs:
Utilization of Other Chained ops -- not hw? https://vscode.dev/github/neel-patel-1/qatlib/blob/dc_chain_sample_app_breakdown/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_chaining_main.c#L1735
VFIO_DEVICE_GET_REGION_INFO ioctl failed ?
CPM
SHRAM Constants table?
Does buffer allocation happen at session initialization time?
- How are the number of descriptors to allocate determined?


Obs:
Complexity of the callback function increases polling time seen by the application
- timestamp in the callback Function
Hypo: 
- response time observed in the callback function will be lowest


Are any other requirements for establishing a sync session besides passing NULL as the cb here?: https://vscode.dev/github/neel-patel-1/qatlib/blob/dc_chain_sample_app_breakdown/quickassist/lookaside/access_layer/src/sample_code/functional/dc/chaining_sample/cpa_chaining_sample.c#L755
NO:
Synchronous or asynchronous operation of the API is determined by
 *  the value of the callbackFn parameter passed to cpaDcChainInitSession()
  *  when the sessionHandle was setup. If a non-NULL value was specified
   *  then the supplied callback function will be invoked asynchronously
    *  with the response of this request
	This function has identical response ordering rules as
	 *  cpaDcCompressData().
https://vscode.dev/github/neel-patel-1/qatlib/blob/dc_chain_sample_app_breakdown/quickassist/include/dc/cpa_dc_chain.h#L658
What are the Response ordering rules?
What takes place in the kernel bottom half? What is a kernel bottom half?

does sync op require app to poll the ring to determine completion? Yes, icp_sal_DcPollInstance is required -- passing NULL just prevents a callback from being registered / called once polling completes

Can we invoke another instance in a callback function ?
- in the callback function we: update a single field pass a pre-prepped descriptor and 
(1) update a field in a preallocated descriptor
(2) call CpaPerformOp




# SYNC Chained Operation Latency
/home/n869p538/spr-accel-profiling/interrupt_qat_dc/qatlib/quickassist/include/dc/cpa_dc_chain.h -- are all of these operations supported?
Which ones are sw/hw?

Compress then Encrypt
```p
#qat config
# Comment or remove next line to disable sriov
#SRIOV_ENABLE=1
POLICY=1
ServicesEnabled=dcc
```

# Polling Breakdown
git checkout polling_breakdown
sudo make samples -j;  sudo ./cpa_sample_code runTests=32 getLatency=1 >& log
awk 'BEGIN{printf("size(B),poll-time(ns)\n");sum=0;count=0;} /^COMPRESS/{print} /^DECOMPRESS/{print; } /.* Size.*/{printf("%s,",$3); if(sum > 0){print sum/count;} sum=0;count=0;} /Average.*/{ if ($5 < 1000000) {sum+=$5;count+=1;}} ' log
# At what granularity is max bandwidth achieved?


# RequestPopulation && Submission Breakdown
Setup: call requests/submissions created/submitted from cpaDcCompressData API
sudo ./latency_sample runTests=32 getLatency=1 >& avg_req_sub_times.log
echo -n "ReqPrep time:"; awk '/16384.\*/ {do_print=1;} {if(do_print==1)print;}' avg_req_sub_times.log | awk -F: '{if(NR%2==0){sum+= $2}} END{print sum/(NR/2)}' avg_req_sub_times.log
echo -n "Sub time:"; awk '/16384.\*/ {do_print=1;} {if(do_print==1)print;}' avg_req_sub_times.log | awk -F: '{if(NR%2==1){sum+= $2}} END{print sum/(NR/2)}' avg_req_sub_times.log


# Synchronous Decompression Latency ( Linux sapphire.ittc.ku.edu 6.5.7-dirty #8 SMP PREEMPT_DYNAMIC Thu Feb 15 10:14:11 CST 2024 x86_64 x86_64 x86_64 GNU/Linux ) (RequestPopulation+Submission && Wait)
=====
- to get RequestPopulation && Submission Separately, checkout [TODO]

Run
=====
git checkout sync_decomp_latency
sudo make samples -j
(base) n869p538@sapphire:qatlib$ ./latency_sample runTests=32 getLatency=1

start cycles: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1206

mark start time of a single request:
https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/common/qat_perf_latency.c#L242
<- https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1018
<-- https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1228

create the request (when called from cpaDcCompressData) :
https://vscode.dev/github/neel-patel-1/qatlib/blob/qat_mwait/quickassist/lookaside/access_layer/src/common/compression/dc_datapath.c#L1871

send the request: https://vscode.dev/github/neel-patel-1/qatlib/blob/qat_mwait/quickassist/lookaside/access_layer/src/common/compression/dc_datapath.c#L1915

submit to QAT: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/common/compression/dc_ns_datapath.c#L1622

poll: https://vscode.dev/github/neel-patel-1/qatlib/blob/main/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1251

get response time of single request: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/cpa_sample_code_dc_utils.c#L218

end cycles: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/cpa_sample_code_dc_utils.c#L247
- after all responses are gathered in the callback function

latencyMode polls for one buffer's completion before starting next submission:
https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/common/qat_perf_latency.c#L73

whole file, one buff, how much?: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1208
-> https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1033

setupDcCommonTest {testSetupData_g[testTypeCount_g].performance_function = (performance_func_t)dcPerformance;}:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L221
<-dcPerformance:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L350 ->
<-qatDcPerform:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L617
<-qatCompressData:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1119
->qatSummariseLatencyMeasurements:
https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1459



createStartandWaitForCompletion:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/framework/cpa_sample_code_framework.c#L1864
<-
----
createPerfomanceThreads{status = sampleCodeThreadCreate(
                &threads_g[numCreatedThreads_g - 1],
                threadAttr,
                functionPtr,
                &singleThreadData_g[numCreatedThreads_g - 1]);}https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/test/cpa_sample_code_framework.c#L1113
waitForThreadCompletion:https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/framework/cpa_sample_code_framework.c#L2009
----
->printDCStats: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/cpa_sample_code_dc_utils.c#L1331




post the semaphore purppose?: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/qat_compression_main.c#L1268

QAT nanosleeps between polling intervals: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/compression/cpa_sample_code_dc_utils.c#L1308
- does removing nanosleep reduce avg latency? No
- does replacing with monitor/mwait reduce avg cpu? -- will perf_data_t -> pollingcycles reveal cycles spent polling?
coo_poll function takes cycle counter using rdtscp every time poll function is called: https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/common/qat_perf_cycles.h#L384
https://vscode.dev/github/neel-patel-1/qatlib/blob/decomp_latency/quickassist/lookaside/access_layer/src/sample_code/performance/common/qat_perf_cycles.h#L168
```
__asm__ volatile(
        "rdtscp\n\t"
        "mov %%edx, %0\n\t"
        "mov %%eax, %1\n\t"
        : "=r"(cycles_high), "=r"(cycles_low)::"%rax", "%rbx", "%rcx", "%rdx");
```


# Comment or remove next line to disable sriov
#SRIOV_ENABLE=1
POLICY=1
ServicesEnabled=dcc

(base) n869p538@sapphire:interrupt_qat_dc$ ./restart_qat.sh
Job for qat.service failed because the control process exited with error code.
See "systemctl status qat.service" and "journalctl -xeu qat.service" for details.
(base) n869p538@sapphire:interrupt_qat_dc$

ERRORS
====
(base) n869p538@sapphire:interrupt_qat_dc$ sudo systemctl start qat
Job for qat.service failed because the control process exited with error code.
See "systemctl status qat.service" and "journalctl -xeu qat.service" for details.
(base) n869p538@sapphire:interrupt_qat_dc$ sudo systemctl status qat.service
× qat.service - QAT service
     Loaded: loaded (/lib/systemd/system/qat.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Fri 2024-03-15 15:42:16 CDT; 4s ago
TriggeredBy: ● qat.timer
× qat.service - QAT service
     Loaded: loaded (/lib/systemd/system/qat.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Fri 2024-03-15 15:42:16 CDT; 4s ago
TriggeredBy: ● qat.timer
    Process: 161027 ExecStartPre=/bin/sh -c test $(getent group qat) (code=exited, status=0/SUCCESS)
    Process: 161029 ExecStartPre=/usr/local/sbin/qat_init.sh (code=exited, status=0/SUCCESS)
    Process: 161327 ExecStart=/usr/local/sbin/qatmgr --policy=${POLICY} (code=exited, status=1/FAILURE)
        CPU: 990ms

Mar 15 15:42:15 sapphire.ittc.ku.edu systemd[1]: Starting QAT service...
Mar 15 15:42:15 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh, device 0000:76:00.0 configured with services: dcc
Mar 15 15:42:15 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh, device 0000:f3:00.0 configured with services: dcc
Mar 15 15:42:16 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh: 364: echo: echo: I/O error
Mar 15 15:42:16 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh: 364: echo: echo: I/O error
Mar 15 15:42:16 sapphire.ittc.ku.edu qatmgr[161329]: No devices found
lines 1-15/19 73%...skipping...
× qat.service - QAT service
     Loaded: loaded (/lib/systemd/system/qat.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Fri 2024-03-15 15:42:16 CDT; 4s ago
TriggeredBy: ● qat.timer
    Process: 161027 ExecStartPre=/bin/sh -c test $(getent group qat) (code=exited, status=0/SUCCESS)
    Process: 161029 ExecStartPre=/usr/local/sbin/qat_init.sh (code=exited, status=0/SUCCESS)
    Process: 161327 ExecStart=/usr/local/sbin/qatmgr --policy=${POLICY} (code=exited, status=1/FAILURE)
        CPU: 990ms

Mar 15 15:42:15 sapphire.ittc.ku.edu systemd[1]: Starting QAT service...
Mar 15 15:42:15 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh, device 0000:76:00.0 configured with services: dcc
Mar 15 15:42:15 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh, device 0000:f3:00.0 configured with services: dcc
Mar 15 15:42:16 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh: 364: echo: echo: I/O error
Mar 15 15:42:16 sapphire.ittc.ku.edu qat_init.sh[161029]: /usr/local/sbin/qat_init.sh: 364: echo: echo: I/O error
Mar 15 15:42:16 sapphire.ittc.ku.edu qatmgr[161329]: No devices found
Mar 15 15:42:16 sapphire.ittc.ku.edu qatmgr[161327]: No QAT device found
Mar 15 15:42:16 sapphire.ittc.ku.edu systemd[1]: qat.service: Control process exited, code=exited, status=1/FAILURE
Mar 15 15:42:16 sapphire.ittc.ku.edu systemd[1]: qat.service: Failed with result 'exit-code'.
Mar 15 15:42:16 sapphire.ittc.ku.edu systemd[1]: Failed to start QAT service.
~
~
~
~
lines 1-19/19 (END)

SOLUTION:
(base) n869p538@sapphire:interrupt_qat_dc$ wget https://git.kernel.org/pub/scm/linux/kernel/git/firmware/linux-firmware.git/plain/qat_4xxx.bin
--2024-03-15 15:56:29--  https://git.kernel.org/pub/scm/linux/kernel/git/firmware/linux-firmware.git/plain/qat_4xxx.bin
Resolving git.kernel.org (git.kernel.org)... 139.178.84.217, 2604:1380:4641:c500::1
Connecting to git.kernel.org (git.kernel.org)|139.178.84.217|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 665356 (650K) [application/octet-stream]
Saving to: ‘qat_4xxx.bin’

qat_4xxx.bin                             100%[===============================================================================>] 649.76K  --.-KB/s    in 0.08s

2024-03-15 15:56:29 (8.17 MB/s) - ‘qat_4xxx.bin’ saved [665356/665356]

(base) n869p538@sapphire:interrupt_qat_dc$ sudo mv qat_4xxx.bin /lib/firmware
(base) n869p538@sapphire:interrupt_qat_dc$ sudo rmmod qat_4xxx intel_qat
(base) n869p538@sapphire:interrupt_qat_dc$ sudo modprobe qat_4xxx
(base) n869p538@sapphire:interrupt_qat_dc$ systemctl restart qat
==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===
Authentication is required to restart 'qat.service'.
Authenticating as: r (tmp)
Password:
(base) n869p538@sapphire:interrupt_qat_dc$ sudo !!
sudo systemctl restart qat
(base) n869p538@sapphire:interrupt_qat_dc$ sudo systemctl restart qat
(base) n869p538@sapphire:interrupt_qat_dc$ sudo systemctl status qat.service
● qat.service - QAT service
     Loaded: loaded (/lib/systemd/system/qat.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2024-03-15 15:57:26 CDT; 39s ago
TriggeredBy: ● qat.timer
    Process: 167094 ExecStartPre=/bin/sh -c test $(getent group qat) (code=exited, status=0/SUCCESS)
    Process: 167096 ExecStartPre=/usr/local/sbin/qat_init.sh (code=exited, status=0/SUCCESS)
    Process: 167806 ExecStart=/usr/local/sbin/qatmgr --policy=${POLICY} (code=exited, status=0/SUCCESS)
   Main PID: 167808 (qatmgr)
      Tasks: 1 (limit: 308979)
     Memory: 1.8M
        CPU: 1.964s
     CGroup: /system.slice/qat.service
             └─167808 /usr/local/sbin/qatmgr --policy=1

Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: Detected DC configuration
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: section 8, BDF 7602
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: Detected DC configuration
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: section 9, BDF F302
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: Detected DC configuration
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: section 10, BDF 760A
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: Detected DC configuration
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: section 11, BDF F30A
Mar 15 15:57:26 sapphire.ittc.ku.edu systemd[1]: Started QAT service.
Mar 15 15:57:26 sapphire.ittc.ku.edu qatmgr[167808]: Detected DC configuration
(base) n869p538@sapphire:interrupt_qat_dc$ sudo modprobe qat_4xxx

TODO:
====
Could have driven up userspace op submit time:
https://vscode.dev/github/neel-patel-1/qatlib/blob/sw_chained_dcc/quickassist/lookaside/access_layer/src/common/compression/dc_chain.c#L1381
